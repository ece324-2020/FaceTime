{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: Tesla T4.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "from torchvision import transforms, utils, datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from rich import print\n",
    "# from rich.progress import track\n",
    "from skimage import io, transform\n",
    "from collections import Counter\n",
    "\n",
    "seed = 100\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "batch_size = 32\n",
    "img_size = 180\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    print('Running on GPU: {}.'.format(torch.cuda.get_device_name()))\n",
    "else:\n",
    "    print('Running on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Images: [('./testdata/Data/face41_bbcdb79c-31e9-11eb-bea8-002432182720.jpg', 0), ('./testdata/Data/face325_6655d44b-31ed-11eb-99dd-002432182720.jpg', 0), ('./testdata/Data/face571_034f932b-31f0-11eb-b19e-002432182720.jpg', 0), ('./testdata/Data/face474_f3ced606-31ee-11eb-8481-002432182720.jpg', 0), ('./testdata/Data/face249_619eb34f-31ec-11eb-be8e-002432182720.jpg', 0)]\n",
      "Labels: {'Data': 0}\n",
      "Number of images: 5485\n"
     ]
    }
   ],
   "source": [
    "def load_data_first_time(img_size, desired=None):\n",
    "    preset_mean = [0.0, 0.0, 0.0]\n",
    "    preset_std = [0.0, 0.0, 0.0]\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "         transforms.Resize(img_size),\n",
    "         transforms.CenterCrop(img_size),\n",
    "         transforms.ToTensor()\n",
    "         ])\n",
    "\n",
    "    imageDataset = torchvision.datasets.ImageFolder(root='./testdata', transform=transform)\n",
    "    \n",
    "    random.shuffle(imageDataset.imgs)\n",
    "\n",
    "\n",
    "    print (\"Sample Images:\", imageDataset.imgs[:5])\n",
    "    print (\"Labels:\", imageDataset.class_to_idx)\n",
    "\n",
    "    num_classes = len(imageDataset.classes)\n",
    "\n",
    "    print (\"Number of images:\",len(imageDataset))\n",
    "    \n",
    "    return imageDataset\n",
    "\n",
    "imageDataset = load_data_first_time(img_size)\n",
    "classes = imageDataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fulldata(img_size, desired=None):\n",
    "    \n",
    "    means = [0.3831, 0.2346, 0.2189]\n",
    "    stds =  [0.2026, 0.1548, 0.1604]\n",
    "\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(img_size),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ])\n",
    "\n",
    "    fulldataset = datasets.ImageFolder(root='./testdata', transform = transform)\n",
    "    random.shuffle(fulldataset.imgs)\n",
    "    \n",
    "    if desired:\n",
    "        for i in range(len(fulldataset)):\n",
    "            img , label = fulldataset.imgs[i]\n",
    "            if label == desired:\n",
    "                fulldataset.imgs[i] = (img, 1)\n",
    "            else:\n",
    "                fulldataset.imgs[i] = (img, 0)\n",
    "    \n",
    "    print (fulldataset.imgs[:15])\n",
    "    \n",
    "    \n",
    "\n",
    "    return fulldataset\n",
    "\n",
    "def get_loaders(data, batch_size):\n",
    "    n = len(data)\n",
    "    \n",
    "    random.shuffle(data.imgs)\n",
    "\n",
    "    test_set  = torch.utils.data.Subset(data, range(n))\n",
    "    \n",
    "    test_loader  = torch.utils.data.DataLoader(test_set,  batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, v, show, loss_fnc, desired=False, sensitivity=False):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    vloss = 0\n",
    "    \n",
    "    ones = torch.ones([batch_size], dtype=torch.long)\n",
    "    neg_ones = -1 * ones\n",
    "    twos = ones + 1\n",
    "    \n",
    "    TPs = 0.\n",
    "    FPs = 0.\n",
    "    FNs = 0.\n",
    "    \n",
    "    TP_dict = Counter()\n",
    "    FN_dict = Counter()\n",
    "    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in v:\n",
    "            images, labels = data\n",
    "            outputs = model(images.type(torch.cuda.FloatTensor))\n",
    "            labels = labels.type(torch.cuda.LongTensor)\n",
    "\n",
    "            vloss += loss_fnc(input=outputs.squeeze(), target=labels)\n",
    "\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "#             print (predicted)\n",
    "            \n",
    "            if sensitivity:\n",
    "                if desired:\n",
    "                    for i in range(len(predicted)):\n",
    "                        if predicted[i] == 1:\n",
    "                            if predicted[i] == labels[i]:\n",
    "                                TPs += 1\n",
    "                            else:\n",
    "                                FNs += 1\n",
    "                else:\n",
    "                    for i in range(len(predicted)):\n",
    "                        if predicted[i] == labels[i]:\n",
    "                            TP_dict[classes[labels[i]]] += 1\n",
    "                        else:\n",
    "                            FN_dict[classes[labels[i]]] += 1\n",
    "                    \n",
    "            lookup = classes\n",
    "\n",
    "            if desired:\n",
    "                lookup = [\"Extra\", classes[desired]]\n",
    "\n",
    "            \n",
    "            if show:\n",
    "                for i in range(len(predicted)):\n",
    "                    if predicted[i] != labels[i]:\n",
    "                        imshow(images[i])\n",
    "                        \n",
    "\n",
    "                        print (\">>>>>>\", lookup[predicted[i]])\n",
    "                        print (\"Truth:\", lookup[labels[i]])\n",
    "    \n",
    "    if sensitivity:\n",
    "        if desired:\n",
    "            print (\"TPs:\", TPs, \"FNs:\", FNs)\n",
    "            if TPs ==0:\n",
    "                return 0, vloss.item()/len(v)\n",
    "            return TPs/(TPs+FNs), vloss.item()/len(v)\n",
    "#             print (float(correct)/float(total))\n",
    "            \n",
    "        else:\n",
    "            sens = {}\n",
    "            avg_sens = 0.\n",
    "            for key in TP_dict.keys():\n",
    "                sens[key] = float(TP_dict[key])/float(TP_dict[key] + FN_dict[key])\n",
    "                avg_sens += sens[key]\n",
    "            print (sens)\n",
    "            print (float(correct)/float(total))\n",
    "            \n",
    "            return avg_sens/float(len(classes)), vloss.item()/len(v)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    return float(correct)/float(total), vloss.item()/len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./testdata/Data/face284_cc008273-31ec-11eb-b675-002432182720.jpg', 0), ('./testdata/Data/face266_9fc8bfec-31ec-11eb-abbb-002432182720.jpg', 0), ('./testdata/Data/face325_448f702a-31ed-11eb-86e4-002432182720.jpg', 0), ('./testdata/Data/face466_e578f8f2-31ee-11eb-a19a-002432182720.jpg', 0), ('./testdata/Data/face152_1d986fc5-31eb-11eb-9ec3-002432182720.jpg', 0), ('./testdata/Data/face118_b78dfb83-31ea-11eb-a5a3-002432182720.jpg', 0), ('./testdata/Data/face559_c6ad36af-31ef-11eb-b1d3-002432182720.jpg', 0), ('./testdata/Data/face316_3658b6ac-31ed-11eb-9b7a-002432182720.jpg', 0), ('./testdata/Data/face325_6594cac1-31ed-11eb-941f-002432182720.jpg', 0), ('./testdata/Data/face22_77f5e7d3-31e9-11eb-8209-002432182720.jpg', 0), ('./testdata/Data/face301_050627a6-31ed-11eb-a77b-002432182720.jpg', 0), ('./testdata/Data/face573_f20c04f8-31ef-11eb-99fb-002432182720.jpg', 0), ('./testdata/Data/face454_c610c014-31ee-11eb-9f6d-002432182720.jpg', 0), ('./testdata/Data/face561_e7fdd6c6-31ef-11eb-a431-002432182720.jpg', 0), ('./testdata/Data/face112_9e6ea37e-31ea-11eb-b6cf-002432182720.jpg', 0)]\n"
     ]
    }
   ],
   "source": [
    "fulldataset = load_fulldata(img_size)\n",
    "# print (fulldataset)\n",
    "test_loader = get_loaders(fulldataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, hidden=32, conv_num=4):\n",
    "        super(BinaryNet, self).__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv_norm1 = nn.BatchNorm2d(20)\n",
    "        self.conv_norm2 = nn.BatchNorm2d(20)\n",
    "        self.conv_norm3 = nn.BatchNorm2d(20)\n",
    "        self.conv_norm4 = nn.BatchNorm2d(20)\n",
    "        \n",
    "        self.conv_norm1.track_running_stats=False\n",
    "        self.conv_norm2.track_running_stats=False\n",
    "        self.conv_norm3.track_running_stats=False\n",
    "        self.conv_norm4.track_running_stats=False\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,  20, 6)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 4)\n",
    "        self.conv3 = nn.Conv2d(20, 20, 3)\n",
    "        self.conv4 = nn.Conv2d(20, 20, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(20*9*9, 400)\n",
    "        self.lin_norm1 = nn.BatchNorm1d(400)\n",
    "        self.fc2 = nn.Linear(400, 20)\n",
    "        self.lin_norm2 = nn.BatchNorm1d(20)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv_norm1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv_norm2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.conv_norm3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.conv_norm4(self.conv4(x))))\n",
    "\n",
    "        x = x.view(-1,20*9*9)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    torch.load('1.pt2'),\n",
    "    torch.load('3.pt2'),\n",
    "    torch.load('4.pt2'),\n",
    "    torch.load('5.pt2'),\n",
    "    torch.load('6.pt2')\n",
    "]\n",
    "lookup = {\n",
    "    'Leonard': 1,\n",
    "    'Penny': 3,\n",
    "    'Raj': 4,\n",
    "    'Sheldon': 5,\n",
    "    'Wolowitz': 6\n",
    "}\n",
    "# list_lookup = [1, 3, 4, 5, 6]\n",
    "\n",
    "list_lookup = [\n",
    "    'Leonard',\n",
    "    'Penny',\n",
    "    'Raj',\n",
    "    'Sheldon',\n",
    "    'Wolowitz'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Leonard': 1022, 'Wolowitz': 697, 'Raj': 651, 'Sheldon': 633, 'Penny': 208})\n"
     ]
    }
   ],
   "source": [
    "onscreen= Counter()\n",
    "threshold = 0.0\n",
    "with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, _ = data\n",
    "            bsize = images.shape[0]\n",
    "            \n",
    "            outputs = []\n",
    "            \n",
    "            for i, model in enumerate(models):\n",
    "                o = model(images.type(torch.cuda.FloatTensor))\n",
    "                outputs.append(o)\n",
    "            \n",
    "            l = []\n",
    "            for i, output in enumerate(outputs):\n",
    "                values, indices = torch.max(output.data, 1)\n",
    "                \n",
    "                values = values.to(torch.device(\"cpu\")).numpy()\n",
    "                indices = indices.to(torch.device(\"cpu\")).numpy()\n",
    "\n",
    "                l.append(values*indices)\n",
    "            \n",
    "            maxes = np.array(l).T\n",
    "            m = torch.from_numpy(maxes)\n",
    "            vals, inds = torch.max(m, 1)\n",
    "#             print (vals)\n",
    "            # so now we can either just add or we can threshold\n",
    "            \n",
    "            for i, ind in enumerate(inds):\n",
    "                if vals[i] > threshold:\n",
    "                    onscreen[list_lookup[ind]] +=1\n",
    "            \n",
    "                \n",
    "print (onscreen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Wolowitz <span style=\"color: #00ff00; font-weight: bold\">0:05:48</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f44780c7490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sheldon <span style=\"color: #00ff00; font-weight: bold\">0:05:16</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f4478c12d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Leonard <span style=\"color: #00ff00; font-weight: bold\">0:08:31</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f44780b8d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Penny <span style=\"color: #00ff00; font-weight: bold\">0:01:44</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f4478c12d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raj <span style=\"color: #00ff00; font-weight: bold\">0:05:25</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f44780b8d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "# from rich import print\n",
    "for key in onscreen.keys():\n",
    "    a = datetime.timedelta(seconds=onscreen[key]//2)\n",
    "    print (key, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sheldon 0:05:12\n",
    "Raj 0:05:08\n",
    "Leonard 0:08:19\n",
    "Wolowitz 0:05:36\n",
    "Penny 0:01:35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1022+697+651+633+208)//2//60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
